Index: Asistente.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>\r\nimport os\r\nimport cv2\r\nimport pyttsx3\r\nimport speech_recognition as sr\r\nimport pywhatkit\r\nimport webbrowser\r\nimport datetime\r\nimport time\r\nimport json\r\nfrom Persona import Persona\r\n\r\nusuarios = list()\r\n\r\n\r\ndef audio_to_text(timeout=10):\r\n    # Recognizer\r\n    r = sr.Recognizer()\r\n\r\n    # Configurar el micrófono\r\n    with sr.Microphone() as origen:\r\n        # Tiempo de espera desde que se activa el micrófono\r\n        r.pause_threshold = 0.5\r\n\r\n        # Informar que comenzó la grabación\r\n        print('Puedes comenzar a hablar')\r\n        start_time = time.time()\r\n\r\n        # Guardar audio\r\n        while time.time() - start_time < timeout:\r\n            audio = r.listen(origen)\r\n            try:\r\n                # Buscar en Google lo escuchado\r\n                text = r.recognize_google(audio, language='es-es')\r\n                print(text)\r\n                return text.lower()\r\n            except sr.UnknownValueError:\r\n                print('Ups, no entendí lo que dijiste')\r\n                return 'Esperando'\r\n            except sr.RequestError:\r\n                print('Ups, sin servicio')\r\n                return 'Esperando'\r\n            except Exception as e:\r\n                print(f'Ups, algo ha salido mal: {e}')\r\n                return 'Esperando'\r\n\r\n        print('Tiempo de espera agotado')\r\n        return 'Esperando'\r\n\r\n\r\ndef talk(msg):\r\n    newVoiceRate = 160\r\n\r\n    engine = pyttsx3.init()\r\n    engine.setProperty('rate', newVoiceRate)\r\n    engine.say(msg)\r\n    engine.runAndWait()\r\n\r\n\r\ndef print_voices():\r\n    engine = pyttsx3.init()\r\n    for voz in engine.getProperty('voices'):\r\n        print(voz.id, voz)\r\n\r\n\r\ndef saludo():\r\n    hour = datetime.datetime.now()\r\n    if hour.hour < 6 or hour.hour > 20:\r\n        momento = 'Buenas noches.'\r\n    elif 6 <= hour.hour < 13:\r\n        momento = 'Buenos días.'\r\n    else:\r\n        momento = 'Buenas tardes.'\r\n\r\n    talk(f'{momento} Soy el bicho, tu asistente personal.')\r\n\r\n\r\ndef guardar_datos_personas(personas):\r\n    dict_instances = {}\r\n    for persona in personas:\r\n        dict_instances[persona.name] = persona.to_dict()\r\n\r\n    result = {'Personas': dict_instances}\r\n\r\n    with open('datos_personas.json', 'w') as json_file:\r\n        json.dump(result, json_file, indent=2)\r\n    talk('Datos de personas guardados exitosamente.')\r\n\r\n\r\ndef cargar_datos_personas():\r\n    try:\r\n        with open('datos_personas.json', 'r') as json_file:\r\n            data = json.load(json_file)\r\n            dict_instances = data.get('Personas', {})\r\n            personas = []\r\n\r\n            for name, persona_data in dict_instances.items():\r\n                nueva_persona = Persona(name, persona_data['image'])\r\n                personas.append(nueva_persona)\r\n\r\n            return personas\r\n    except FileNotFoundError:\r\n        return []\r\n\r\n\r\ndef registro():\r\n    talk('Dime tu nombre, por favor.')\r\n\r\n    # Establecer un límite de tiempo para la entrada del nombre (10 segundos en este caso)\r\n    name = audio_to_text(timeout=10).lower()\r\n\r\n    if name == 'esperando':\r\n        talk('No se ha podido capturar correctamente tu nombre. Por favor, intenta nuevamente.')\r\n        return None\r\n\r\n    print(name)\r\n    ruta_imagen, result = takePhoto(name)\r\n\r\n    if result:\r\n        newUser = Persona(name, ruta_imagen)\r\n        usuarios.append(newUser)\r\n        mensaje = f'{name} registrado exitosamente.'\r\n        talk(mensaje)\r\n        return newUser\r\n    else:\r\n        talk('El registro no ha podido realizarse correctamente.')\r\n        return None\r\n\r\n\r\ndef takePhoto(name):\r\n    # Crear la carpeta \"caras\" si no existe\r\n    if not os.path.exists(\"caras\"):\r\n        os.makedirs(\"caras\")\r\n\r\n    # Abre la cámara\r\n    cap = cv2.VideoCapture(0)\r\n    if not cap.isOpened():\r\n        talk(\"Error: No se pudo abrir la cámara.\")\r\n        return None, False\r\n\r\n    # Intenta establecer una tasa de fotogramas más alta\r\n    cap.set(cv2.CAP_PROP_FPS, 120)\r\n\r\n    # Muestra la vista previa de la cámara\r\n    talk(\"Preparándose para tomar la foto. Por favor, sonríe.\")\r\n\r\n    # Crea una ventana para mostrar la vista previa\r\n    cv2.namedWindow('Reconocimiento Facial', cv2.WINDOW_NORMAL)\r\n\r\n    # Inicia un bucle para mostrar la transmisión en tiempo real durante la cuenta atrás\r\n    for i in range(4, 0, -1):\r\n        # Captura un fotograma\r\n        ret, frame = cap.read()\r\n        if not ret:\r\n            talk(\"Error al capturar la foto.\")\r\n            break\r\n\r\n        # Muestra la imagen actualizada en la ventana\r\n        cv2.imshow('Reconocimiento Facial', frame)\r\n\r\n        # Espera 1 segundo entre cada cuenta regresiva\r\n        time.sleep(1)\r\n        talk(str(i))\r\n\r\n    # Cierra la ventana de vista previa\r\n    cv2.destroyWindow('Reconocimiento Facial')\r\n\r\n    # Captura un solo fotograma después de la cuenta atrás\r\n    ret, frame = cap.read()\r\n    if ret:\r\n        # Guarda la foto en la carpeta \"caras\"\r\n        cv2.imwrite(os.path.join(\"caras\", f\"{name}.jpg\"), frame)\r\n        talk(f\"Foto capturada y guardada como 'caras/{name}.jpg'\")\r\n        # Libera la cámara\r\n        cap.release()\r\n        return frame, True\r\n    else:\r\n        talk(\"Error al capturar la foto.\")\r\n        # Libera la cámara\r\n        cap.release()\r\n        return None, False\r\n\r\n\r\ndef comprobarRegistro():\r\n    talk('¿Qué usuario deseas comprobar?')\r\n    name = audio_to_text().lower()\r\n    found = False\r\n    for p in usuarios:\r\n        if p.name == name:\r\n            found = True\r\n    return found\r\n\r\n\r\ndef showUsers():\r\n    for persona in usuarios:\r\n        print(persona.name)\r\n\r\n\r\ndef requests():\r\n    saludo()\r\n    stop = False\r\n    while not stop:\r\n        talk('¿Qué deseas hacer?')\r\n        request = audio_to_text().lower()\r\n        print(request)\r\n        if 'abrir youtube' in request:\r\n            talk('Abriendo youtube')\r\n            webbrowser.open('https://www.youtube.com')\r\n        elif 'salir' in request:\r\n            talk('Hasta luego bombón')\r\n            guardar_datos_personas(usuarios)\r\n            exit()\r\n        elif 'registrarse' in request:\r\n            nueva_persona = registro()\r\n            if nueva_persona:\r\n                usuarios.append(nueva_persona)\r\n                guardar_datos_personas(usuarios)\r\n        elif 'comprobar registro' in request:\r\n            if comprobarRegistro():\r\n                talk('El usuario está registrado en el sistema')\r\n            else:\r\n                talk('El usuario no está registrado en el sistema')\r\n        elif 'listar usuarios' in request:\r\n            showUsers()\r\n            talk('Estos son los usuarios registrados:')\r\n            for persona in usuarios:\r\n                talk(persona.name)\r\n\r\n\r\n\r\n\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Asistente.py b/Asistente.py
--- a/Asistente.py	(revision ac1c5fe79776ba5548eeee47861342d2fd0f14e1)
+++ b/Asistente.py	(date 1706119179096)
@@ -1,53 +1,52 @@
-
-import os
 import cv2
 import pyttsx3
 import speech_recognition as sr
-import pywhatkit
 import webbrowser
 import datetime
 import time
-import json
+
 from Persona import Persona
 
+
 usuarios = list()
 
-
-def audio_to_text(timeout=10):
+# Escuchar micro y devolver audio como texto
+def audio_to_text():
     # Recognizer
     r = sr.Recognizer()
 
-    # Configurar el micrófono
+    # Configurar el micro
     with sr.Microphone() as origen:
-        # Tiempo de espera desde que se activa el micrófono
+        # Tiempo de espera desde que se activa el micro
         r.pause_threshold = 0.5
 
         # Informar que comenzó la grabación
         print('Puedes comenzar a hablar')
-        start_time = time.time()
-
         # Guardar audio
-        while time.time() - start_time < timeout:
-            audio = r.listen(origen)
-            try:
-                # Buscar en Google lo escuchado
-                text = r.recognize_google(audio, language='es-es')
-                print(text)
-                return text.lower()
-            except sr.UnknownValueError:
-                print('Ups, no entendí lo que dijiste')
-                return 'Esperando'
-            except sr.RequestError:
-                print('Ups, sin servicio')
-                return 'Esperando'
-            except Exception as e:
-                print(f'Ups, algo ha salido mal: {e}')
-                return 'Esperando'
+        audio = r.listen(origen, )
+        try:
+            # Buscar en google lo escuchado
+            text = r.recognize_google(audio, language='es-es')
+            print(text)
+            return text
+        except sr.UnknownValueError:
+            print('Ups, no entendí lo que dijiste')
+            return 'Esperando'
+
+        except sr.RequestError:
+            print('Ups, sin servicio')
+            return 'Esperando'
 
-        print('Tiempo de espera agotado')
-        return 'Esperando'
+        except:
+            print('Ups, algo ha salido mal')
+            return 'Esperando'
 
 
+
+
+
+
+
 def talk(msg):
     newVoiceRate = 160
 
@@ -57,13 +56,21 @@
     engine.runAndWait()
 
 
+
+
+
+
 def print_voices():
     engine = pyttsx3.init()
     for voz in engine.getProperty('voices'):
         print(voz.id, voz)
 
 
+
+
+
 def saludo():
+
     hour = datetime.datetime.now()
     if hour.hour < 6 or hour.hour > 20:
         momento = 'Buenas noches.'
@@ -75,114 +82,51 @@
     talk(f'{momento} Soy el bicho, tu asistente personal.')
 
 
-def guardar_datos_personas(personas):
-    dict_instances = {}
-    for persona in personas:
-        dict_instances[persona.name] = persona.to_dict()
-
-    result = {'Personas': dict_instances}
 
-    with open('datos_personas.json', 'w') as json_file:
-        json.dump(result, json_file, indent=2)
-    talk('Datos de personas guardados exitosamente.')
-
-
-def cargar_datos_personas():
-    try:
-        with open('datos_personas.json', 'r') as json_file:
-            data = json.load(json_file)
-            dict_instances = data.get('Personas', {})
-            personas = []
-
-            for name, persona_data in dict_instances.items():
-                nueva_persona = Persona(name, persona_data['image'])
-                personas.append(nueva_persona)
-
-            return personas
-    except FileNotFoundError:
-        return []
 
 
 def registro():
-    talk('Dime tu nombre, por favor.')
-
-    # Establecer un límite de tiempo para la entrada del nombre (10 segundos en este caso)
-    name = audio_to_text(timeout=10).lower()
-
-    if name == 'esperando':
-        talk('No se ha podido capturar correctamente tu nombre. Por favor, intenta nuevamente.')
-        return None
-
+    talk('Dime tu nombre cariño')
+    name = audio_to_text().lower()
     print(name)
-    ruta_imagen, result = takePhoto(name)
-
-    if result:
-        newUser = Persona(name, ruta_imagen)
-        usuarios.append(newUser)
-        mensaje = f'{name} registrado exitosamente.'
-        talk(mensaje)
-        return newUser
-    else:
-        talk('El registro no ha podido realizarse correctamente.')
-        return None
+    usuarios.append(Persona(name, ""))
+    mensaje  = f'{name} registrado exitosamente'
+    talk(mensaje)
+    return Persona(name, "")
 
 
-def takePhoto(name):
-    # Crear la carpeta "caras" si no existe
-    if not os.path.exists("caras"):
-        os.makedirs("caras")
 
+
+def takePhoto():
     # Abre la cámara
     cap = cv2.VideoCapture(0)
     if not cap.isOpened():
         talk("Error: No se pudo abrir la cámara.")
-        return None, False
-
-    # Intenta establecer una tasa de fotogramas más alta
-    cap.set(cv2.CAP_PROP_FPS, 120)
+        return
 
     # Muestra la vista previa de la cámara
     talk("Preparándose para tomar la foto. Por favor, sonríe.")
-
-    # Crea una ventana para mostrar la vista previa
-    cv2.namedWindow('Reconocimiento Facial', cv2.WINDOW_NORMAL)
-
-    # Inicia un bucle para mostrar la transmisión en tiempo real durante la cuenta atrás
-    for i in range(4, 0, -1):
-        # Captura un fotograma
-        ret, frame = cap.read()
-        if not ret:
-            talk("Error al capturar la foto.")
-            break
-
-        # Muestra la imagen actualizada en la ventana
-        cv2.imshow('Reconocimiento Facial', frame)
-
-        # Espera 1 segundo entre cada cuenta regresiva
-        time.sleep(1)
+    for i in range(3, 0, -1):
         talk(str(i))
+        #time.sleep(250)
 
-    # Cierra la ventana de vista previa
-    cv2.destroyWindow('Reconocimiento Facial')
-
-    # Captura un solo fotograma después de la cuenta atrás
+    # Captura un solo fotograma
     ret, frame = cap.read()
     if ret:
-        # Guarda la foto en la carpeta "caras"
-        cv2.imwrite(os.path.join("caras", f"{name}.jpg"), frame)
-        talk(f"Foto capturada y guardada como 'caras/{name}.jpg'")
-        # Libera la cámara
-        cap.release()
-        return frame, True
+        # Guarda la foto
+        cv2.imwrite("foto_capturada.jpg", frame)
+        talk("Foto capturada y guardada como 'foto_capturada.jpg'")
     else:
         talk("Error al capturar la foto.")
-        # Libera la cámara
-        cap.release()
-        return None, False
+
+    # Libera la cámara
+    cap.release()
+
+# Resto del código...
 
 
 def comprobarRegistro():
-    talk('¿Qué usuario deseas comprobar?')
+    talk('¿Que usuario deseas comprobar?')
     name = audio_to_text().lower()
     found = False
     for p in usuarios:
@@ -190,7 +134,6 @@
             found = True
     return found
 
-
 def showUsers():
     for persona in usuarios:
         print(persona.name)
@@ -207,14 +150,10 @@
             talk('Abriendo youtube')
             webbrowser.open('https://www.youtube.com')
         elif 'salir' in request:
-            talk('Hasta luego bombón')
-            guardar_datos_personas(usuarios)
+            talk('Hasta luégo, bombón')
             exit()
         elif 'registrarse' in request:
-            nueva_persona = registro()
-            if nueva_persona:
-                usuarios.append(nueva_persona)
-                guardar_datos_personas(usuarios)
+            registro()
         elif 'comprobar registro' in request:
             if comprobarRegistro():
                 talk('El usuario está registrado en el sistema')
@@ -222,10 +161,8 @@
                 talk('El usuario no está registrado en el sistema')
         elif 'listar usuarios' in request:
             showUsers()
-            talk('Estos son los usuarios registrados:')
-            for persona in usuarios:
-                talk(persona.name)
-
+        elif 'tomar foto' in request:
+            takePhoto()
 
 
 
Index: .idea/shelf/Uncommitted_changes_before_Update_at_17_01_2024_16_30__Changes_.xml
===================================================================
diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_17_01_2024_16_30__Changes_.xml b/.idea/shelf/Uncommitted_changes_before_Update_at_17_01_2024_16_30__Changes_.xml
deleted file mode 100644
--- a/.idea/shelf/Uncommitted_changes_before_Update_at_17_01_2024_16_30__Changes_.xml	(revision ac1c5fe79776ba5548eeee47861342d2fd0f14e1)
+++ /dev/null	(revision ac1c5fe79776ba5548eeee47861342d2fd0f14e1)
@@ -1,4 +0,0 @@
-<changelist name="Uncommitted_changes_before_Update_at_17_01_2024_16_30_[Changes]" date="1705505458140" recycled="true" deleted="true">
-  <option name="PATH" value="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_17_01_2024_16_30_[Changes]/shelved.patch" />
-  <option name="DESCRIPTION" value="Uncommitted changes before Update at 17/01/2024 16:30 [Changes]" />
-</changelist>
\ No newline at end of file
Index: .idea/shelf/Uncommitted_changes_before_Update_at_17_01_2024_16_30_[Changes]/shelved.patch
===================================================================
diff --git a/.idea/shelf/Uncommitted_changes_before_Update_at_17_01_2024_16_30_[Changes]/shelved.patch b/.idea/shelf/Uncommitted_changes_before_Update_at_17_01_2024_16_30_[Changes]/shelved.patch
deleted file mode 100644
--- a/.idea/shelf/Uncommitted_changes_before_Update_at_17_01_2024_16_30_[Changes]/shelved.patch	(revision ac1c5fe79776ba5548eeee47861342d2fd0f14e1)
+++ /dev/null	(revision ac1c5fe79776ba5548eeee47861342d2fd0f14e1)
@@ -1,60 +0,0 @@
-Index: main.py
-IDEA additional info:
-Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
-<+>import cv2\r\nimport os\r\nimport speech_recognition as sr\r\n\r\nclass AsistenteScrum:\r\n    def __init__(self):\r\n        self.usuarios_registrados = {}\r\n\r\n    def reconocer_usuario_con_camara(self):\r\n        # Inicializar el clasificador facial de OpenCV\r\n        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\r\n\r\n        # Inicializar la cámara\r\n        cap = cv2.VideoCapture(0)\r\n\r\n        while True:\r\n            # Capturar el fotograma\r\n            ret, frame = cap.read()\r\n\r\n            # Convertir a escala de grises para el reconocimiento facial\r\n            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\r\n\r\n            # Detectar rostros en el fotograma\r\n            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30))\r\n\r\n            for (x, y, w, h) in faces:\r\n                # Dibujar un rectángulo alrededor del rostro detectado\r\n                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\r\n\r\n                # Recortar la región del rostro\r\n                roi_gray = gray[y:y+h, x:x+w]\r\n\r\n                # Devolver el nombre del usuario si es reconocido\r\n                nombre_usuario = self.reconocer_usuario_en_imagen(roi_gray)\r\n                if nombre_usuario:\r\n                    cap.release()\r\n                    cv2.destroyAllWindows()\r\n                    return nombre_usuario\r\n\r\n            # Mostrar el fotograma con el rectángulo alrededor del rostro\r\n            cv2.imshow('Reconocimiento Facial', frame)\r\n\r\n            # Salir si se presiona la tecla 'Esc'\r\n            if cv2.waitKey(1) == 27:\r\n                cap.release()\r\n                cv2.destroyAllWindows()\r\n                return None\r\n\r\ndef reconocer_usuario_en_imagen(self, imagen):\r\n    for nombre_usuario, datos_usuario in self.usuarios_registrados.items():\r\n        foto_registrada = cv2.imread(datos_usuario['foto'], cv2.IMREAD_GRAYSCALE)\r\n        # Aquí puedes utilizar algún método de comparación de características, como la \t\tcorrelación\r\n        correlacion = cv2.matchTemplate(imagen, foto_registrada, cv2.TM_CCOEFF_NORMED)\r\n        if correlacion > umbral_de_correlacion:\r\n            return nombre_usuario\r\n    return None\r\n\r\n    def capturar_imagen(self, nombre_usuario):\r\n        # Inicializar la cámara\r\n        cap = cv2.VideoCapture(0)\r\n\r\n        # Capturar el fotograma\r\n        ret, frame = cap.read()\r\n\r\n        # Guardar la imagen en un archivo\r\n        ruta_imagen = self.reconstruir_nombre_imagen(nombre_usuario)\r\n        cv2.imwrite(ruta_imagen, frame)\r\n\r\n        cap.release()\r\n        cv2.destroyAllWindows()\r\n\r\n        return ruta_imagen\r\n\r\n    def reconstruir_nombre_imagen(self, nombre_usuario):\r\n        return f\"{nombre_usuario.replace(' ', '_')}.jpg\"\r\n\r\n    def reconocer_voz(self):\r\n        recognizer = sr.Recognizer()\r\n\r\n        with sr.Microphone() as source:\r\n            print(\"Escuchando... Di una orden:\")\r\n            audio = recognizer.listen(source)\r\n\r\n        try:\r\n            orden = recognizer.recognize_google(audio, language=\"es-ES\").lower()\r\n            return orden\r\n        except sr.UnknownValueError:\r\n            return \"No se pudo entender la orden\"\r\n        except sr.RequestError as e:\r\n            return f\"Error en la solicitud de reconocimiento de voz: {e}\"\r\n\r\n    def controlar_asistencia(self):\r\n        orden = self.reconocer_voz()\r\n\r\n        if \"controlar asistencia\" in orden:\r\n            nombre_usuario = self.reconocer_usuario_con_camara()\r\n\r\n            if nombre_usuario:\r\n                print(f\"Bienvenido, {nombre_usuario}.\")\r\n            else:\r\n                print(\"Usuario no reconocido. ¿Desea registrarse?\")\r\n\r\n    def registrar_usuario(self):\r\n        orden = self.reconocer_voz()\r\n\r\n        if \"registrar usuario\" in orden:\r\n            nombre_usuario = input(\"Dime tu nombre: \")\r\n            datos_personales = input(\"Dime tus datos personales: \")\r\n\r\n            ruta_imagen = self.capturar_imagen(nombre_usuario)\r\n\r\n            self.usuarios_registrados[nombre_usuario] = {\r\n                'datos_personales': datos_personales,\r\n                'foto': ruta_imagen\r\n            }\r\n            print(f\"Usuario {nombre_usuario} registrado con éxito.\")\r\n\r\n    def salir_aplicacion(self):\r\n        orden = self.reconocer_voz()\r\n\r\n        if \"salir de la aplicación\" in orden:\r\n            print(\"Hasta luego. Gracias por usar la aplicación.\")\r\n            exit()\r\n\r\n# Ejemplo de uso\r\nasistente = AsistenteScrum()\r\n\r\nwhile True:\r\n    asistente.controlar_asistencia()\r\n    asistente.registrar_usuario()\r\n    asistente.salir_aplicacion()
-Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
-<+>UTF-8
-===================================================================
-diff --git a/main.py b/main.py
---- a/main.py	(revision 2626c2346b294f94670a5fbf71a97c9e67b07dfb)
-+++ b/main.py	(date 1705419717627)
-@@ -46,14 +46,15 @@
-                 cv2.destroyAllWindows()
-                 return None
- 
--def reconocer_usuario_en_imagen(self, imagen):
--    for nombre_usuario, datos_usuario in self.usuarios_registrados.items():
--        foto_registrada = cv2.imread(datos_usuario['foto'], cv2.IMREAD_GRAYSCALE)
--        # Aquí puedes utilizar algún método de comparación de características, como la 		correlación
--        correlacion = cv2.matchTemplate(imagen, foto_registrada, cv2.TM_CCOEFF_NORMED)
--        if correlacion > umbral_de_correlacion:
--            return nombre_usuario
--    return None
-+    def reconocer_usuario_en_imagen(self, imagen):
-+        for nombre_usuario, datos_usuario in self.usuarios_registrados.items():
-+            foto_registrada = cv2.imread(datos_usuario['foto'], cv2.IMREAD_GRAYSCALE)
-+            # Aquí puedes utilizar algún método de comparación de características, como la correlación
-+            correlacion = cv2.matchTemplate(imagen, foto_registrada, cv2.TM_CCOEFF_NORMED)
-+            # if correlacion > umbral_de_correlacion:
-+            if correlacion > 0.6:
-+                return nombre_usuario
-+        return None
- 
-     def capturar_imagen(self, nombre_usuario):
-         # Inicializar la cámara
-@@ -83,6 +84,7 @@
- 
-         try:
-             orden = recognizer.recognize_google(audio, language="es-ES").lower()
-+            print(f"Orden reconocida por voz: {orden}")  # Mensaje de depuración
-             return orden
-         except sr.UnknownValueError:
-             return "No se pudo entender la orden"
-@@ -91,8 +93,10 @@
- 
-     def controlar_asistencia(self):
-         orden = self.reconocer_voz()
-+        print(f"Orden reconocida: {orden}")  # Mensaje de depuración
- 
-         if "controlar asistencia" in orden:
-+            print("Iniciando reconocimiento facial...")  # Mensaje de depuración
-             nombre_usuario = self.reconocer_usuario_con_camara()
- 
-             if nombre_usuario:
-@@ -128,4 +132,4 @@
- while True:
-     asistente.controlar_asistencia()
-     asistente.registrar_usuario()
--    asistente.salir_aplicacion()
-\ No newline at end of file
-+    asistente.salir_aplicacion()
Index: .idea/misc.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<project version=\"4\">\r\n  <component name=\"Black\">\r\n    <option name=\"sdkName\" value=\"Python 3.10\" />\r\n  </component>\r\n  <component name=\"ProjectRootManager\" version=\"2\" project-jdk-name=\"Python 3.10\" project-jdk-type=\"Python SDK\" />\r\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/misc.xml b/.idea/misc.xml
--- a/.idea/misc.xml	(revision ac1c5fe79776ba5548eeee47861342d2fd0f14e1)
+++ b/.idea/misc.xml	(date 1705949235686)
@@ -1,7 +1,7 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <project version="4">
   <component name="Black">
-    <option name="sdkName" value="Python 3.10" />
+    <option name="sdkName" value="Python 3.12" />
   </component>
-  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.10" project-jdk-type="Python SDK" />
+  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.12 (SGE_Reconocimiento) (2)" project-jdk-type="Python SDK" />
 </project>
\ No newline at end of file
Index: .idea/workspace.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<project version=\"4\">\r\n  <component name=\"AutoImportSettings\">\r\n    <option name=\"autoReloadType\" value=\"SELECTIVE\" />\r\n  </component>\r\n  <component name=\"ChangeListManager\">\r\n    <list default=\"true\" id=\"a3f0a12a-3167-4b59-ae80-44ba719021a9\" name=\"Changes\" comment=\"Camara activada\">\r\n      <change beforePath=\"$PROJECT_DIR$/.idea/misc.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/misc.xml\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_17_01_2024_20_39__Changes_.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_17_01_2024_20_39__Changes_.xml\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_17_01_2024_20_39__Changes_1.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_17_01_2024_20_39__Changes_1.xml\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_17_01_2024_16_30__Changes_.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_17_01_2024_16_30__Changes_.xml\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/.idea/workspace.xml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/.idea/workspace.xml\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/Asistente.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/Asistente.py\" afterDir=\"false\" />\r\n      <change beforePath=\"$PROJECT_DIR$/Persona.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/Persona.py\" afterDir=\"false\" />\r\n    </list>\r\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\r\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\r\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\r\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\r\n  </component>\r\n  <component name=\"FileTemplateManagerImpl\">\r\n    <option name=\"RECENT_TEMPLATES\">\r\n      <list>\r\n        <option value=\"Python Script\" />\r\n      </list>\r\n    </option>\r\n  </component>\r\n  <component name=\"Git.Settings\">\r\n    <option name=\"RECENT_BRANCH_BY_REPOSITORY\">\r\n      <map>\r\n        <entry key=\"$PROJECT_DIR$\" value=\"main\" />\r\n      </map>\r\n    </option>\r\n    <option name=\"RECENT_GIT_ROOT_PATH\" value=\"$PROJECT_DIR$\" />\r\n  </component>\r\n  <component name=\"MarkdownSettingsMigration\">\r\n    <option name=\"stateVersion\" value=\"1\" />\r\n  </component>\r\n  <component name=\"ProjectColorInfo\">{\r\n  &quot;associatedIndex&quot;: 4\r\n}</component>\r\n  <component name=\"ProjectId\" id=\"2b2FLwVPA3jwW5H55TnlsUcxTSU\" />\r\n  <component name=\"ProjectViewState\">\r\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\r\n    <option name=\"showLibraryContents\" value=\"true\" />\r\n  </component>\r\n  <component name=\"PropertiesComponent\"><![CDATA[{\r\n  \"keyToString\": {\r\n    \"Python.main.executor\": \"Run\",\r\n    \"RunOnceActivity.OpenProjectViewOnStart\": \"true\",\r\n    \"RunOnceActivity.ShowReadmeOnStart\": \"true\",\r\n    \"git-widget-placeholder\": \"jose__tarea1\",\r\n    \"last_opened_file_path\": \"C:/Users/Miguel/PycharmProjects/SGE_Reconocimiento\",\r\n    \"node.js.detected.package.eslint\": \"true\",\r\n    \"node.js.detected.package.tslint\": \"true\",\r\n    \"node.js.selected.package.eslint\": \"(autodetect)\",\r\n    \"node.js.selected.package.tslint\": \"(autodetect)\",\r\n    \"nodejs_package_manager_path\": \"npm\",\r\n    \"settings.editor.selected.configurable\": \"com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable\",\r\n    \"vue.rearranger.settings.migration\": \"true\"\r\n  }\r\n}]]></component>\r\n  <component name=\"RunManager\">\r\n    <configuration name=\"main\" type=\"PythonConfigurationType\" factoryName=\"Python\" nameIsGenerated=\"true\">\r\n      <module name=\"SGE_Reconocimiento\" />\r\n      <option name=\"ENV_FILES\" value=\"\" />\r\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\r\n      <option name=\"PARENT_ENVS\" value=\"true\" />\r\n      <envs>\r\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\r\n      </envs>\r\n      <option name=\"SDK_HOME\" value=\"\" />\r\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$\" />\r\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\r\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\r\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\r\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\r\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/main.py\" />\r\n      <option name=\"PARAMETERS\" value=\"\" />\r\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\r\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\r\n      <option name=\"MODULE_MODE\" value=\"false\" />\r\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\r\n      <option name=\"INPUT_FILE\" value=\"\" />\r\n      <method v=\"2\" />\r\n    </configuration>\r\n  </component>\r\n  <component name=\"SharedIndexes\">\r\n    <attachedChunks>\r\n      <set>\r\n        <option value=\"bundled-python-sdk-50da183f06c8-2887949eec09-com.jetbrains.pycharm.pro.sharedIndexes.bundled-PY-233.13135.95\" />\r\n      </set>\r\n    </attachedChunks>\r\n  </component>\r\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"application-level\" UseSingleDictionary=\"true\" transferred=\"true\" />\r\n  <component name=\"TaskManager\">\r\n    <task active=\"true\" id=\"Default\" summary=\"Default task\">\r\n      <changelist id=\"a3f0a12a-3167-4b59-ae80-44ba719021a9\" name=\"Changes\" comment=\"\" />\r\n      <created>1705405215052</created>\r\n      <option name=\"number\" value=\"Default\" />\r\n      <option name=\"presentableId\" value=\"Default\" />\r\n      <updated>1705405215052</updated>\r\n      <workItem from=\"1705410644813\" duration=\"502000\" />\r\n      <workItem from=\"1705416073913\" duration=\"748000\" />\r\n      <workItem from=\"1705417232323\" duration=\"44000\" />\r\n      <workItem from=\"1705417813751\" duration=\"2206000\" />\r\n      <workItem from=\"1705500402331\" duration=\"2425000\" />\r\n      <workItem from=\"1705517271818\" duration=\"1507000\" />\r\n    </task>\r\n    <task id=\"LOCAL-00001\" summary=\"Camara activada\">\r\n      <option name=\"closed\" value=\"true\" />\r\n      <created>1705506946676</created>\r\n      <option name=\"number\" value=\"00001\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00001\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1705506946676</updated>\r\n    </task>\r\n    <task id=\"LOCAL-00002\" summary=\"Camara activada\">\r\n      <option name=\"closed\" value=\"true\" />\r\n      <created>1705506967820</created>\r\n      <option name=\"number\" value=\"00002\" />\r\n      <option name=\"presentableId\" value=\"LOCAL-00002\" />\r\n      <option name=\"project\" value=\"LOCAL\" />\r\n      <updated>1705506967820</updated>\r\n    </task>\r\n    <option name=\"localTasksCounter\" value=\"3\" />\r\n    <servers />\r\n  </component>\r\n  <component name=\"TypeScriptGeneratedFilesManager\">\r\n    <option name=\"version\" value=\"3\" />\r\n  </component>\r\n  <component name=\"Vcs.Log.Tabs.Properties\">\r\n    <option name=\"TAB_STATES\">\r\n      <map>\r\n        <entry key=\"MAIN\">\r\n          <value>\r\n            <State />\r\n          </value>\r\n        </entry>\r\n      </map>\r\n    </option>\r\n  </component>\r\n  <component name=\"VcsManagerConfiguration\">\r\n    <MESSAGE value=\"Camara activada\" />\r\n    <option name=\"LAST_COMMIT_MESSAGE\" value=\"Camara activada\" />\r\n  </component>\r\n  <component name=\"com.intellij.coverage.CoverageDataManagerImpl\">\r\n    <SUITE FILE_PATH=\"coverage/SGE_Reconocimiento$main.coverage\" NAME=\"main Coverage Results\" MODIFIED=\"1705518551070\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\r\n  </component>\r\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/workspace.xml b/.idea/workspace.xml
--- a/.idea/workspace.xml	(revision ac1c5fe79776ba5548eeee47861342d2fd0f14e1)
+++ b/.idea/workspace.xml	(date 1706119179479)
@@ -6,12 +6,8 @@
   <component name="ChangeListManager">
     <list default="true" id="a3f0a12a-3167-4b59-ae80-44ba719021a9" name="Changes" comment="Camara activada">
       <change beforePath="$PROJECT_DIR$/.idea/misc.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/misc.xml" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_17_01_2024_20_39__Changes_.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_17_01_2024_20_39__Changes_.xml" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_17_01_2024_20_39__Changes_1.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Checkout_at_17_01_2024_20_39__Changes_1.xml" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_17_01_2024_16_30__Changes_.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/shelf/Uncommitted_changes_before_Update_at_17_01_2024_16_30__Changes_.xml" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
       <change beforePath="$PROJECT_DIR$/Asistente.py" beforeDir="false" afterPath="$PROJECT_DIR$/Asistente.py" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/Persona.py" beforeDir="false" afterPath="$PROJECT_DIR$/Persona.py" afterDir="false" />
     </list>
     <option name="SHOW_DIALOG" value="false" />
     <option name="HIGHLIGHT_CONFLICTS" value="true" />
@@ -44,22 +40,22 @@
     <option name="hideEmptyMiddlePackages" value="true" />
     <option name="showLibraryContents" value="true" />
   </component>
-  <component name="PropertiesComponent"><![CDATA[{
-  "keyToString": {
-    "Python.main.executor": "Run",
-    "RunOnceActivity.OpenProjectViewOnStart": "true",
-    "RunOnceActivity.ShowReadmeOnStart": "true",
-    "git-widget-placeholder": "jose__tarea1",
-    "last_opened_file_path": "C:/Users/Miguel/PycharmProjects/SGE_Reconocimiento",
-    "node.js.detected.package.eslint": "true",
-    "node.js.detected.package.tslint": "true",
-    "node.js.selected.package.eslint": "(autodetect)",
-    "node.js.selected.package.tslint": "(autodetect)",
-    "nodejs_package_manager_path": "npm",
-    "settings.editor.selected.configurable": "com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable",
-    "vue.rearranger.settings.migration": "true"
+  <component name="PropertiesComponent">{
+  &quot;keyToString&quot;: {
+    &quot;Python.main.executor&quot;: &quot;Run&quot;,
+    &quot;RunOnceActivity.OpenProjectViewOnStart&quot;: &quot;true&quot;,
+    &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,
+    &quot;git-widget-placeholder&quot;: &quot;jose__tarea1&quot;,
+    &quot;last_opened_file_path&quot;: &quot;C:/Users/Miguel/PycharmProjects/SGE_Reconocimiento&quot;,
+    &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,
+    &quot;node.js.detected.package.tslint&quot;: &quot;true&quot;,
+    &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,
+    &quot;node.js.selected.package.tslint&quot;: &quot;(autodetect)&quot;,
+    &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,
+    &quot;settings.editor.selected.configurable&quot;: &quot;com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable&quot;,
+    &quot;vue.rearranger.settings.migration&quot;: &quot;true&quot;
   }
-}]]></component>
+}</component>
   <component name="RunManager">
     <configuration name="main" type="PythonConfigurationType" factoryName="Python" nameIsGenerated="true">
       <module name="SGE_Reconocimiento" />
@@ -128,17 +124,6 @@
   </component>
   <component name="TypeScriptGeneratedFilesManager">
     <option name="version" value="3" />
-  </component>
-  <component name="Vcs.Log.Tabs.Properties">
-    <option name="TAB_STATES">
-      <map>
-        <entry key="MAIN">
-          <value>
-            <State />
-          </value>
-        </entry>
-      </map>
-    </option>
   </component>
   <component name="VcsManagerConfiguration">
     <MESSAGE value="Camara activada" />
