Index: Asistente.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import cv2\r\nimport pyttsx3\r\nimport speech_recognition as sr\r\nimport pywhatkit\r\nimport webbrowser\r\nimport datetime\r\nimport time\r\nimport json\r\nfrom PIL import Image\r\nimport time\r\nfrom Persona import Persona\r\nimport os\r\nusuarios = list()\r\n\r\ndef audio_to_text(timeout=10):\r\n    # Recognizer\r\n    r = sr.Recognizer()\r\n\r\n    # Configurar el micro\r\n    with sr.Microphone() as origen:\r\n        # Tiempo de espera desde que se activa el micro\r\n        r.pause_threshold = 0.5\r\n\r\n        # Informar que comenzó la grabación\r\n        print('Puedes comenzar a hablar')\r\n        start_time = time.time()\r\n\r\n        # Guardar audio\r\n        while time.time() - start_time < timeout:\r\n            audio = r.listen(origen)\r\n            try:\r\n                # Buscar en google lo escuchado\r\n                text = r.recognize_google(audio, language='es-es')\r\n                print(text)\r\n                return text.lower()\r\n            except sr.UnknownValueError:\r\n                print('Ups, no entendí lo que dijiste')\r\n                return 'Esperando'\r\n            except sr.RequestError:\r\n                print('Ups, sin servicio')\r\n                return 'Esperando'\r\n            except Exception as e:\r\n                print(f'Ups, algo ha salido mal: {e}')\r\n                return 'Esperando'\r\n\r\n        print('Tiempo de espera agotado')\r\n        return 'Esperando'\r\n\r\n\r\n\r\ndef talk(msg):\r\n    newVoiceRate = 160\r\n\r\n    engine = pyttsx3.init()\r\n    engine.setProperty('rate', newVoiceRate)\r\n    engine.say(msg)\r\n    engine.runAndWait()\r\n\r\n\r\ndef print_voices():\r\n    engine = pyttsx3.init()\r\n    for voz in engine.getProperty('voices'):\r\n        print(voz.id, voz)\r\n\r\ndef saludo():\r\n\r\n    hour = datetime.datetime.now()\r\n    if hour.hour < 6 or hour.hour > 20:\r\n        momento = 'Buenas noches.'\r\n    elif 6 <= hour.hour < 13:\r\n        momento = 'Buenos días.'\r\n    else:\r\n        momento = 'Buenas tardes.'\r\n\r\n    talk(f'{momento} Soy el bicho, tu asistente personal.')\r\n\r\n\r\n\r\ndef guardar_datos_personas(personas):\r\n    dict_instances = {}\r\n    for persona in personas:\r\n        dict_instances[persona.name] = persona.to_dict()\r\n        dict_instances[persona.image] = persona.to_dict()\r\n\r\n    result = {'Persona': dict_instances}\r\n\r\n    with open('datos_personas.json', 'w') as json_file:\r\n        json.dump(result, json_file, indent=2)\r\n    talk('Datos de personas guardados exitosamente.')\r\n\r\ndef cargar_datos_personas():\r\n    try:\r\n        with open('datos_personas.json', 'r') as json_file:\r\n            data = json.load(json_file)\r\n            dict_instances = data.get('Persona', {})  # Utilizar la clave 'Persona'\r\n            personas = []\r\n\r\n            for name, persona_data in dict_instances.items():\r\n                nueva_persona = Persona(name, persona_data['image'])\r\n                personas.append(nueva_persona)\r\n\r\n            return personas\r\n    except FileNotFoundError:\r\n        return []\r\n\r\ndef registro():\r\n    talk('Dime tu nombre, por favor.')\r\n\r\n    # Establecer un límite de tiempo para la entrada del nombre (10 segundos en este caso)\r\n    name = audio_to_text(timeout=10).lower()\r\n\r\n    if name == 'esperando':\r\n        talk('No se ha podido capturar correctamente tu nombre. Por favor, intenta nuevamente.')\r\n        return None\r\n\r\n    print(name)\r\n    ruta_imagen, result = takePhoto(name)\r\n\r\n    if result:\r\n        newUser = Persona(name, ruta_imagen)\r\n        usuarios.append(newUser)\r\n        mensaje = f'{name} registrado exitosamente.'\r\n        talk(mensaje)\r\n        return newUser  # Devolver la nueva persona creada\r\n    else:\r\n        talk('El registro no ha podido realizarse correctamente.')\r\n        return None\r\n\r\n\r\ndef takePhoto(name):\r\n    # Abre la cámara\r\n    cap = cv2.VideoCapture(0)\r\n    if not cap.isOpened():\r\n        talk(\"Error: No se pudo abrir la cámara.\")\r\n        return None, False\r\n\r\n    # Intenta establecer una tasa de fotogramas más alta\r\n    cap.set(cv2.CAP_PROP_FPS, 120)  # Ajusta a 30 FPS, puedes experimentar con otros valores\r\n\r\n    # Muestra la vista previa de la cámara\r\n    talk(\"Preparándose para tomar la foto. Por favor, sonríe.\")\r\n\r\n    # Crea una ventana para mostrar la vista previa\r\n    cv2.namedWindow('Reconocimiento Facial', cv2.WINDOW_NORMAL)\r\n\r\n    # Inicia un bucle para mostrar la transmisión en tiempo real durante la cuenta atrás\r\n    for i in range(4, 0, -1):\r\n        # Captura un fotograma\r\n        ret, frame = cap.read()\r\n        if not ret:\r\n            talk(\"Error al capturar la foto.\")\r\n            break\r\n\r\n        # Muestra la imagen actualizada en la ventana\r\n        cv2.imshow('Reconocimiento Facial', frame)\r\n\r\n        # Espera 1 segundo entre cada cuenta regresiva\r\n        time.sleep(1)\r\n        talk(str(i))\r\n\r\n    # Cierra la ventana de vista previa\r\n    cv2.destroyWindow('Reconocimiento Facial')\r\n\r\n    # Captura un solo fotograma después de la cuenta atrás\r\n    ret, frame = cap.read()\r\n    if ret:\r\n        # Guarda la foto\r\n        cv2.imwrite(f\"{name}.jpg\", frame)\r\n        talk(f\"Foto capturada y guardada como '{name}.jpg'\")\r\n        # Libera la cámara\r\n        cap.release()\r\n        return frame, True\r\n    else:\r\n        talk(\"Error al capturar la foto.\")\r\n        # Libera la cámara\r\n        cap.release()\r\n        return None, False\r\n\r\ndef comprobarRegistro():\r\n    talk('¿Que usuario deseas comprobar?')\r\n    name = audio_to_text().lower()\r\n    found = False\r\n    for p in usuarios:\r\n        if p.name == name:\r\n            found = True\r\n    return found\r\n\r\ndef showUsers():\r\n    for persona in usuarios:\r\n        print(persona.name)\r\n\r\n\r\ndef requests():\r\n    saludo()\r\n    stop = False\r\n    while not stop:\r\n        talk('¿Qué deseas hacer?')\r\n        request = audio_to_text().lower()\r\n        print(request)\r\n        if 'abrir youtube' in request:\r\n            talk('Abriendo youtube')\r\n            webbrowser.open('https://www.youtube.com')\r\n        elif 'salir' in request:\r\n            talk('Hasta luego bombón')\r\n            # Guardar la información antes de salir\r\n            guardar_datos_personas(usuarios)\r\n            exit()\r\n        elif 'registrarse' in request:\r\n            nueva_persona = registro()\r\n            if nueva_persona:\r\n                usuarios.append(nueva_persona)\r\n                # Guardar la información después de registrar\r\n                guardar_datos_personas(usuarios)\r\n        elif 'comprobar registro' in request:\r\n            if comprobarRegistro():\r\n                talk('El usuario está registrado en el sistema')\r\n            else:\r\n                talk('El usuario no está registrado en el sistema')\r\n        elif 'listar usuarios' in request:\r\n            showUsers()\r\n            talk('Estos son los usuarios registrados:')\r\n            for persona in usuarios:\r\n                talk(persona.name)\r\n\r\n\r\n\r\n\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Asistente.py b/Asistente.py
--- a/Asistente.py	
+++ b/Asistente.py	
@@ -1,12 +1,12 @@
 import cv2
 import pyttsx3
 import speech_recognition as sr
-import pywhatkit
+
 import webbrowser
 import datetime
 import time
 import json
-from PIL import Image
+
 import time
 from Persona import Persona
 import os
